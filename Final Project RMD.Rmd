---
title: "Descriptive, Interesting Title"
author: "Trevor Riordan, Ray Wang"
date: "2023-05-26"
output: pdf_document
header-includes: \usepackage{setspace}\doublespacing
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(LearnBayes)
```

# Abstract

# Keywords

# Introduction
  COVID-19 emerged at the end of 2019 as a global threat to humanity. Hospitals were overwhelmed, economies shut down, and hundreds of thousands died from the virus in just the first few months of the pandemic. In 2020, COVID was the third leading cause of death in the United States with over 350,000 confirmed deaths due to COVID (https://www.cdc.gov/nchs/products/databriefs/db427.htm). The need for prevention tactics was obvious and utterly necessary to save lives and help slow down the extreme social and economic damage done by the virus. Very quickly, large biotechnology companies like Pfizer and BioNTech intended to test their vaccine candidates with the intent to prove vaccine efficacy is not 30%, since the FDA requires at least a  30% efficacy in new treatments, and obtain approval for an emergency use authorization. So, BioNTech and Pfizer performed a multinational, placebo-controlled, observer-blinded, pivotal efficacy trial randomly assigning those age 16 or older to either a vaccine or placebo group in a 1:1 ratio. Those in the vaccine group were given two doses of the mRNA vaccine 21 days apart and those in the placebo were given two doses of saline solution 21 days apart. Efficacy was primarily measured as the efficacy in preventing COVID rather than dealing with already confirmed, severe COVID cases. Thus, the data is measured on those who received both doses of either the placebo or mRNA vaccine without major protocol deviations (such that the population could not be evaluated, for example in those with HIV) who had no previous indication of infection within 7 days after the second dose. All acceptable candidates are expected to report and be tested for COVID infection at any time 7 days after the second dose of the vaccine. From this, efficacy can be estimated by comparing the rate of infection between the vaccine and placebo groups. 
  Pfizer and BioNTech's team estimated efficacy to be 95% with a 95% Bayesian credible interval ranging from 90.3 to 97.6. From the same results used in the team's Bayesian analysis, we will perform a diverse set of statistical methods to compare the scientist's efficacy claims with our own findings using confidence intervals and hypothesis testing. We will perform similar Bayesian analysis using the same prior distribution to verify the claims made by the scientists as well as explore different prior distributions to determine how the team's original choice of an informative prior compares to an uninformative prior or other informative priors. We are curious in determining how the choice of prior affects the probability of the null hypothesis being true as well the 95% confidence interval for vaccine efficacy. In addition to similar Bayesian analysis, we will perform nonparametric bootstrapping to generate multiple confidence intervals for vaccine efficacy, and we will compare these intervals with the intervals provided by the team of scientists. Finally, we will perform frequentist analysis to generate a maximum likelihood estimate and a confidence interval for efficacy.  Additionally, we will perform hypothesis testing using the likelihood ratio test to determine the probability of the null being true given our data. All of our hypothesis testing is based on the efficacy statistic where the null states the efficacy is 30%, and for Bayesian analysis the alternative hypothesis states efficacy is greater than 30%, while for the likelihood ratio test the alternative hypothesis states true efficacy is not equal to 30%. So, we will use a multitude of statistical methods comparing and contrasting our methods' estimates and intervals with the claimed estimates and intervals as well as verify the claims made about the null hypothesis's truth. 
  
# Statistical Methods and Calculations

## Data Overview
Our analysis is based on the following table from the referenced paper detailing the efficacy of the COVID vaccine:

\begin{table}[h]
\centering
\begin{tabular}{ccc} \hline
Group & Cases & No. of Subjects \\ \hline
BNT162b2 & 8 & 17411 \\ \hline
Placebo & 162 & 17511 \\ \hline
Total & 170 & 34922 \\ \hline
\end{tabular}
\end{table}

The data shows that 17,411 patients were given the vaccine while 17,511 were given a placebo for a total of 34,922 patients. Of the patients given the vaccine, 8 contracted COVID. Of the patients given the placebo, 162 contracted COVID. There were a total of 170 COVID cases. From the table we can see that both groups have a low rate of contracting COVID ( < 1% each). Additionally, of the 170 COVID cases, less than 5% (8) came from the vaccinated group.

## Bayesian 

This section details our Bayesian analysis methods including verification of results and criticism of prior distribution used in the referenced paper. We are interested in a few different possible prior distributions: the first we chose is an uninformative prior. The uninformative prior, which is a beta distribution with $\alpha = \beta = 1$, allows for massive uncertainty in our potential values for $\pi_0$ with a 95% confidence interval ranging from 0.025 to 0.0975. This corresponds to potential efficacy values ranging from -28 to 0.974359 with 95% confidence. This makes sense in the context of our problem since the way efficacy is defined in our scope, it can take possible values from $-\infty$ (when $\pi_1$ is 1 and $\pi_2$ is 0) to 1 (when $\pi_2$ is 1 and $\pi_1$ is 0). Additionally, the median of this uninformative prior is $\pi_0 = 0.5$, which corresponds to an efficacy of 0. Thus, the uninformative prior has a median efficacy of 0 with potential values ranging from -28 to 0.974359 with 95% confidence where each efficacy value has equal probability of occurring. 

The second prior distribution we will analyze is the same one used in the referenced paper. The team of scientists decided to use a Beta prior distribution with $\alpha = 0.700102$ and $\beta = 1$. Note the expected value of this distribution is $\pi_0 = 0.4118$. Plugging in $\psi = \frac{1 - 2\pi_0}{1-\pi_0}$ yields $\psi=0.3$. Thus, the prior distribution used in the referenced paper is centered about the efficacy value under the null hypothesis. This distribution has a 95% confidence interval for $\pi_0$ ranging from 0.005148 to 0.964483, which is a very similar sized interval for $\pi_0$ as the uninformative prior and thus a fairly uninformative prior distribution, with a corresponding efficacy interval ranging from -26.155565 to 0.994825. So, the prior distribution used in the paper is centered about an efficacy of 0.3, which is the efficacy under the null, and is a fairly uninformative distribution.  

The next prior distribution we explored is a pessimistic unimodal, symmetric beta distribution centered about an efficacy value of 0 with the 95th percentile efficacy value of 0.3. This is a pessimistic, somewhat informative prior distribution suggesting that we initially expect the vaccine to have no effect whatsoever. To be centered about an efficacy of 0 this requires that $P(\psi > 0) = 0.5$, since $\psi = \frac{1 - 2\pi_0}{1-\pi_0}$, we can substitute $\psi$ for $\frac{1 - 2\pi_0}{1-\pi_0}$ and get the value $x$ such that $P(\pi_0 < x) = 0.5$. We can use a similar substitution into $P(\psi > 0.3) = 0.05$ to solve for the value $y$ such that $P(\pi_0 < y) = 0.95$. These calculations are detailed below: 

\begin{align*}
P(\psi > 0) &= 0.5 \\
P(\frac{1 - 2\pi_0}{1-\pi_0} > 0) = 0.5 \\
P(1 - 2\pi_0 > 0) = 0.5 \\
P(2\pi_0 < 1) = 0.5 \\
P(\pi_0 < 0.5) = 0.5 \\
&\text{Similarly,} \\
P(\psi > 0.3) = 0.05 \\
P(\frac{1 - 2\pi_0}{1-\pi_0} > 0.3) = 0.05 \\
P(1 - 2\pi_0 > 0.3 - 0.3\pi_0) = 0.05 \\
P(0.7 > 1.7 \pi_0) = 0.05 \\
P(\pi_0 < \frac{0.7}{1.7} = 0.4118) = 0.05 
\end{align*}

Thus, converting values of $\psi$ to value of $\pi_0$ gives us two quantiles for our prior distribution. From these two quantiles we can calculate the parameters for our prior beta distribution for $\pi_0$. See code chunk 1 in the Appendix for the code to generate these parameters. From the two quantiles we can see the prior distribution is a beta distribution with parameters $\alpha = \beta = 43.04$. This prior distribution is significantly more informative than the uninformative prior with potential values for $\pi_0$ ranging from 0.395247 to 0.604754 with 95% confidence (which is a significantly smaller interval for $\pi_0$ than the uninformative prior and referenced paper's prior, indicating this prior is more informative than both) corresponding to a 95% confidence interval for efficacy ranging from -0.530067 to 0.346434. Since our prior confidence interval for efficacy is so pessimistic with the high end of the interval barely greater than 0.3, a Bayesian credible interval with a lower bound greater than 0.3 would indicate our data is highly significant and we would have very compelling evidence the true efficacy is greater than 0.3.

In the spirit of extreme pessimism, we decided to create an even more pessimistic beta prior centered about an efficacy of -0.5 and with a 95th percentile efficacy value of -0.2. This is an extraordinarily pessimistic prior distribution in which we expect the probability of contracting COVID in the vaccinated group to be 50% more likely than contracting COVID in the control group, meaning the vaccine actually increases the probability of contracting COVID.The calculations for the two quantiles in terms of $\pi_0$ to determine the parameters of our prior distribution is below:

\begin{align*}
P(\psi > -0.5) &= 0.5 \\
P(\frac{1 - 2\pi_0}{1-\pi_0} > -0.5) = 0.5 \\
P(1 - 2\pi_0 > -0.5 + 0.5 \pi_0) = 0.5 \\
P(1.5 \pi_0 < 2.5) = 0.5 \\
P(\pi_0 < 0.6) = 0.5 \\
&\text{Similarly,} \\
P(\psi > -0.2) = 0.05 \\
P(\frac{1 - 2\pi_0}{1-\pi_0} > -0.2) = 0.05 \\
P(1 - 2\pi_0 > -0.2 + 0.2 \pi_0) = 0.05 \\
P(1.2 > 2.2 \pi_0) = 0.05 \\
P(\pi_0 < \frac{1.2}{2.2} = \frac{6}{11} = 0.545455) = 0.05 
\end{align*}
Thus, the 50th percentile of the distribution is $-0.5$ and the 95th percentile of the distribution is $-0.2$. Similarly to before, see code chunk 1 in the Appendix for the code in calculating these parameters. Thus, the prior distribution given these quantiles is a beta distribution with $\alpha = 134.47$ and $\beta = 89.76$. This prior generated a 95% confidence interval for $\pi_0$ ranging from 0.534932 to 0.662777, which is the smallest 95% confidence interval for $\pi_0$ and thus most informative prior distribution, corresponding to a 95% confidence interval for efficacy ranging from -0.965398 to -0.150221. This is the most informative and most pessimistic prior distribution we are testing, and rejecting the null hypothesis given this prior is extremely strong evidence in favor of the alternative hypothesis.

From each of these prior distributions, we can calculate the posterior distribution for $\pi_0$ using Theorem 26.2 which states given $T ~ Binom(n, \pi_0)$ is our likelihood, and our prior for $\pi_0$ is a Beta distribution with shape parameters $\alpha$ and $\beta$, the posterior distribution for $\pi_0$ is a Beta distribution with shape parameters $\alpha + t$ and $\beta + n - t$ where $t$ is the observed value for $T$. From this posterior distribution, we intend to calculate our estimate for $\pi_0$ as the median of our posterior distribution as well as report a 95% Bayesian credible interval for $\pi_0$ ranging from the 2.5th to the 97.5th percentile. We will then convert these values of $\pi$ into $\psi$ using $\psi = \frac{1 - 2 \pi_0}{1 - \pi_0}$ to get an estimated efficacy and an associated 95% Bayesian credible interval. Additionally, for each posterior distribution we will calculate the probability the null hypothesis is true by calculating $P(\psi < 0.3)$, which corresponds to $P(\pi > 0.4118)$. We will then compare the estimates and intervals generated from each prior distribution and compare them in the results section.

```{r}
qbeta(p=c(0.025, 0.975), shape1 = 0.700102, shape2=1)
efficacy_upper <- (1 - 2 * 0.005148448  ) / (1 - 0.005148448  )
efficacy_lower <- (1 - 2 * 0.964483043 ) / (1 - 0.964483043)
c(efficacy_lower, efficacy_upper)
beta.select(quantile1 = list(p=0.5, x=0.6),
            quantile2 = list(p=0.05, x=0.5454545))

posterior_credible <- qbeta(p=c(0.025, 0.975), shape1 = 134.47 + 8, shape2=89.76 + 170 - 8)
posterior_credible
```

## Nonparametric Bootstrapping

This section details the method of nonparametric bootstrapping to generate two forms of confidence intervals providing insight into the true efficacy rate of the vaccine. From Table 2 of the referenced paper we are given two groups of patients: those given the vaccine and those given placebo. From those given the vaccine we can measure the number who got COVID and call this value x and from those given the placebo we can measure the same thing, calling this value y. Then, because there are a fixed number of patients per group who either contract COVID (which is considered the "success" here) or not, and under the assumption that every patient has equal probability of contracting COVID and that the result of one patient does not impact any others, we can model X, the number of COVID cases from the vaccine group, and Y, the number of COVID cases from the placebo group, as binomial distributions. From the table we can see there are 17411 patients given the vaccine and 17511 given the placebo. Thus, $X \sim Binom(17411, \pi_1)$ and $Y \sim Binom(17511, \pi_2)$ where $\pi_1$ is the probability of any given patient with the vaccine contracting COVID and $\pi_2$ is the probability of contracting COVID given the placebo. We can then measure efficacy, $\psi$, as the reduction in probability of contracting COVID given the vaccine compared to the placebo by $\psi = \frac{\pi_2 - \pi_1}{\pi_2}$. We know the expected value for a random variable $Z$ from a binomial distribution with $n$ trials and $\pi_0$ probability of success is $n \pi_0$. Using method of moments to equate the sample mean, $\bar{z}$, to the expected value, we get that an estimate for $\pi_0$ is $\hat{\pi_0}^{mom} = \frac{\bar{z}}{n}$. Using this method, we can generate an estimate for $\psi$ from our given data. Using our data as a single sample from the population, we can see $\bar{x} = 8$ and $\bar{y} = 162$, thus $\hat{\pi_1} = \frac{8}{17411}$ and $\hat{\pi_2} = \frac{162}{17511}$, indicating the rate of COVID contraction is low for both populations. Thus, the initial estimate for $\psi$, $\hat{\psi} = 0.950334$. Treating the given data as the population data, we can sample data of the same size as the original samples with replacement from the observed $X$ and the observed $Y$ samples (as binary vectors of respective lengths with respective proportions of 1s and 0s), each 10,000 times. From each of these 10,000 bootstrapped samples from $X$ and $Y$, we can calculate an estimate for both $\pi_1$ and $\pi_2$ and thus create 10,000 sampled $\hat{\psi} = \frac{\hat{\pi_2} - \hat{\pi_1}}{\hat{\pi_2}}$. From these 10,000 samples we can calculate the standard error of $\hat{\psi}$. Since we have a large number of observations (10,000), we know the distribution of $\hat{\psi}$ is approximately normal, so we can create a 95% Wald's confidence interval by adding or subtracting the standard error multiplied by 1.96 to or from our observed efficacy value, $\hat{\psi} = 0.950334$, to generate a range of values we are 95% confident contains the true efficacy of the vaccine. Additionally, we can create a 95% confidence interval ranging from the 2.5th to the 97.5th quantile of our 10,000 sampled $\hat{\psi}$ which we are 95% confident contains the true efficacy of the vaccine.

## Maximum Likelihood Estimator and Hypothesis Testing

This section details the use of the maximum likelihood estimator for $\psi$ generating the most probable $\psi$ given our observed data. Additionally, we will perform hypothesis testing in the form of a likelihood ratio test evaluating the how extreme our data is under the null, indicating how unlikely the null hypothesis may be. For maximum likelihood estimation, we aggregate our observed data into a single binomial distribution where we measure the number of COVID cases in the vaccine group once we reached a total number of COVID cases across both groups (170 in our case). Let T be the number of patients in the vaccine group out of all patients who contracted COVID, then, $T \sim Binom(S=170, \pi_0)$ where $S=162 + 8 = 170$ is the total number of patients who contracted COVID from our data and $\pi_0 = \frac{\pi_1}{\pi_1 + \pi_2}$ represents the probability of being in the vaccine group given the patient contracted COVID (this is the probability of having the vaccine and COVID divided by the total probability of contracting COVID, regardless of group). We can prove that $T$ follows this distribution with the use of Bayes rule seen in Equation 1 of the Appendix. From $\pi_0 = \frac{\pi_1}{\pi_1 + \pi_2}$ we can solve for $\pi_2$ and substitute for $\pi_2$ to get an expression for $\psi$ in terms of $\pi_0$ and $\pi_0$ in terms of $\psi$:

\begin{align*}
\pi_0 &= \frac{\pi_1}{\pi_1 + \pi_2} \\
\pi_0(\pi_1 + \pi_2) &= \pi_1 \\
\pi_0 \pi_2 &= \pi_1 (1 - \pi_0) \\
\pi_2 &= \frac{\pi_1(1 - \pi_0)}{\pi_0} \\
& \text{ so, } \\
\psi &= \frac{\pi_2 - \pi_1}{\pi_2} \\
&= \frac{\frac{\pi_1(1 - \pi_0)}{\pi_0} - \pi_1}{\frac{\pi_1(1 - \pi_0)}{\pi_0}} \\
&= \frac{\pi_0 * (\frac{\pi_1(1 - \pi_0)}{\pi_0} - \pi_1)}{\pi_1 * (1-\pi_0)} \\
&= \frac{\pi_1 (1-\pi_0) - \pi_0 \pi_1}{\pi_1 (1-\pi_0)} \\
&= \frac{\pi_1 (1-\pi_0 - \pi_0)}{1-\pi_0} \\
&= \frac{1 - 2\pi_0}{1-\pi_0} \\
& \text{ even further,} \\
\psi ( 1- \pi_0) &= 1 - 2\pi_0 \\
\pi_0 (\psi - 2) &= \psi - 1 \\
\pi_0 &= \frac{\psi - 1}{\psi - 2}
\end{align*}

Thus, $\psi = \frac{1- 2\pi_0}{1-\pi_0}$ and $\pi_0 = \frac{\psi - 1}{\psi - 2}$. Hence, $T \sim Binom(170, \pi_0 = \frac{\psi - 1}{\psi - 2})$.  Because $T \sim Binom(170, \pi_0 = \frac{\psi - 1}{\psi - 2})$ and we have only observation for $t = 8 = \text{Number of Patients Given Vaccine Out of All COVID Cases}$, substituting $\pi_0 = \frac{\psi - 1}{\psi - 2}$ and $t=8$ into $f(t) = \binom{170}{t} * \pi_0^t * (1-\pi_0)^{170-t}$ yields the likelihood function $L(\psi) = \binom{170}{8} * (\frac{\psi - 1}{\psi - 2})^8 * (1 - \frac{\psi - 1}{\psi - 2}))^{170 - 8}$. Thus, the log-likelihood function $\ell(\psi) = \ln(\binom{170}{8}) + 8 * \ln(\frac{\psi - 1}{\psi - 2}) + 162 \ln(1-(\frac{\psi - 1}{\psi - 2}))$. Taking the derivative of the log-likelihood function with respect to $\psi$ and setting it equal to 0 to solve for the maximum likelihood estimator for $\psi$ yields $\hat{\psi}^{mle} = \frac{77}{81}$, as seen in Equation 2 of the Appendix.

To verify this is the maximum and to calculate the standard error of $\hat{\psi}^{mle}$, we need to take the second derivative of $\ell(\psi)$ with respect to $\psi$, and plug in our $\hat{\psi}^{mle}$. As seen in Equation 3 of the Appendix, $\ell '' (\psi) = \frac{16\psi -24}{(\psi^2 -3\psi + 2)^2} + \frac{162}{\psi-2)^2}$. Plugging in our estimate of $\hat{\psi}^{mle} = \frac{77}{81}$ into $\ell''(\psi)$ yields $\ell''(\hat{\psi}^{mle}) = -3126.126$. Since this value is negative, $\hat{\psi}^{mle} = \frac{77}{81}$ is a global maximum. Additionally, $SE(\hat{\psi}^{mle}) = \sqrt{\frac{-1}{\ell '' (\hat{\psi}^{mle})}} = 0.01788532$. From our initial estimate and given standard error, we can create a 95% Wald's confidence interval for $\psi$ ranging from $\hat{\psi}^{mle} - 1.96 * SE(\hat{\psi}^{mle})$ to $\hat{\psi}^{mle} + 1.96 * SE(\hat{\psi}^{mle})$. Thus, our 95% confidence interval for $\psi$ is $(0.9155621, 0.9856725)$.

Next, we will perform hypothesis testing using the likelihood ratio test using $H_0: \psi = 0.3$ and $H_a: \psi \neq 0.3$ at the 5% level of significance. We will calculate the likelihood ratio statistic, $W = 2 [\ell(\hat{\psi}^{mle}) - \ell(\psi^{null})]$. From this observed $W$ statistic, we can calculate the probability of observing data as or more extreme than our observed data since $W \sim \chi_1^2$. We know from previous that $\ell(\psi) = \ln(\binom{170}{8}) + 8 * \ln(\frac{\psi - 1}{\psi - 2}) + 162 \ln(1-(\frac{\psi - 1}{\psi - 2}))$. Plugging in our observed value for $t=8$ along with our respective values for $\hat{\psi}^{mle} = \frac{77}{81}$ and $\psi^{null} = 0.3$ allows us to calculate our observed $W = 2 (-1.944994 + 62.7456) = 121.6012$. Then, to calculate the probability of observing data as or more extreme than our observed W, we look at the probability of observing a value greater than or equal to our observed $W$ since larger values are more evidence for the alternative hypothesis. Then, we will calculate the p-value as 'pchisq(W, df=1, lower.tail=FALSE)`, generating a p-value of $2.822313 * 10^{-28}$. 

# Results

## Bayesian Results

First, we'll examine our uninformative prior $Beta(0, 1) = Unif(0, 1)$. The median of our posterior distribution is $0.946707$, while the 95% confidence interval for the posterior distribution corresponding with this prior is $(0.9009794, 0.9750466)$, which rejects the null hypothesis. The $P(\psi < 0.3)$ given our posterior distribution is $1.9422e-28$, so our one-sided p-value rejects the null hypothesis and determines that the true efficacy is greater than $0.3$. In the figure below, we plot the prior and posterior distributions:

```{r Bayesian uniform figure, echo=FALSE}

x <- seq(0, 1, length.out = 1000)

pdf_beta1 <- dbeta(x, 1, 1)
pdf_beta2 <- dbeta(x, 8 + 1, 170 - 8 + 1)

plot(x, pdf_beta1, type = "l", col = "blue", lwd = 2, ylab = "Density", xlab = expression(pi), xlim = c(0, 1), ylim=c(0, 25))
lines(x, pdf_beta2, col = "red", lwd = 2)
legend("topright", legend = c("Prior", "Posterior"), col = c("blue", "red"), lwd = 2)
```

Note that because our prior distribution is extremely uninformative, our posterior distribution is extremely precise and centered at a very low value of $\pi$, which results in a 95% confidence interval that only contains extremely high values of $\psi$. This is in concordance with our results from before.

Now we will examine the prior distribution used by the study, which was $Beta(0.700102, 1)$. The median of our posterior distribution is $0.9485501$, while the 95% confidence interval for the posterior distribution corresponding with this prior is $(0.9035199, 0.9762552)$, which rejects the null hypothesis. The $P(\psi < 0.3)$ given our posterior distribution is $1.9422e-28$, so our one-sided p-value rejects the null hypothesis and determines that the true efficacy is greater than $0.3$. Our prior distribution is also extremely uninformative, so we expect extreme values in our confidence interval and our p-value. In the figure below, we plot the prior and posterior distributions:

```{r Bayesian study figure, echo=FALSE}

x <- seq(0, 1, length.out = 1000)

pdf_beta1 <- dbeta(x, 0.700102, 1)
pdf_beta2 <- dbeta(x, 8 + 0.700102, 170 - 8 + 1)

plot(x, pdf_beta1, type = "l", col = "blue", lwd = 2, ylab = "Density", xlab = expression(pi), xlim = c(0, 1), ylim=c(0, 25))
lines(x, pdf_beta2, col = "red", lwd = 2)
legend("topright", legend = c("Prior", "Posterior"), col = c("blue", "red"), lwd = 2)
```

Our graphs are very similar to the graphs for the uniform prior distribution. The only difference is a slight spike in the prior where $\pi = 0$. Because our distributions are so similar, we expect to obtain similar results for our significance test and confidence interval to the ones we obtained for the uniform prior. Indeed, our results our similar.

Next, we will examine the informative and pessimistic prior distribution $Beta(43.04, 43.04)$. The median of our posterior distribution given our informative and pessimistic prior is $0.752294$, while the 95% confidence interval is $(0.4994181, 0.6944378)$, which rejects the null hypothesis. The $P(\psi < 0.3)$ given our posterior distribution is $1.923758e-13$, so our one-sided p-value rejects the null hypothesis and determines that the true efficacy is greater than $0.3$. Because our prior distribution is more pessimistic, our confidence interval and p-value are not as extreme as the ones we obtained for our previous uninformative priors. In the figure below, we plot the prior and posterior distributions:

```{r Bayesian med0 figure, echo=FALSE}

x <- seq(0, 1, length.out = 1000)

pdf_beta1 <- dbeta(x, 43.04, 43.04)
pdf_beta2 <- dbeta(x, 8 + 43.04, 170 - 8 + 43.04)

plot(x, pdf_beta1, type = "l", col = "blue", lwd = 2, ylab = "Density", xlab = expression(pi), xlim = c(0, 1), ylim=c(0, 20))
lines(x, pdf_beta2, col = "red", lwd = 2)
legend("topright", legend = c("Prior", "Posterior"), col = c("blue", "red"), lwd = 2)
```

Note that because our prior distribution is more informative, our posterior distribution has more spread. Our posterior distribution is also centered on a higher value of $\pi$, which would be a lower value of $\psi$. This is in concordance with the confidence interval we calculated earlier, and it makes sense because our prior distribution is more pessimistic.

Finally, we examine our most pessimistic model $Beta(134.47, 89.76)$, where we consider the possibility that $\psi$ can be negative. The median of our posterior distribution given this prior is $0.752294$, while the 95% confidence interval is $(0.4994181, 0.6944378)$, which rejects the null hypothesis. The $P(\psi < 0.3)$ given our posterior distribution is $0.01986187$, so our one-sided p-value rejects the null hypothesis and determines that the true efficacy is greater than $0.3$. This is the most striking result in our findings, as even when we consider a prior distribution with a mean of $\psi = -0.5$ and a $0.95$ quantile of $\psi = -0.2$, we still reject a null hypothesis of $\psi = 0.3$. Our analysis demonstrates just how the evidence in the study was. In the figure below, we plot the prior and posterior distributions:

```{r Bayesian pessimistic figure, echo=FALSE}

x <- seq(0, 1, length.out = 1000)

pdf_beta1 <- dbeta(x, 134.47, 89.76)
pdf_beta2 <- dbeta(x, 8 + 134.47, 170 - 8 + 89.76)

plot(x, pdf_beta1, type = "l", col = "blue", lwd = 2, ylab = "Density", xlab = expression(pi), xlim = c(0, 1), ylim=c(0, 20))
lines(x, pdf_beta2, col = "red", lwd = 2)
legend("topright", legend = c("Prior", "Posterior"), col = c("blue", "red"), lwd = 2)
```

Our posterior distribution has more spread than our uniform and $Beta(0.700102, 1)$ prior distributions because our prior distribution $\Beta(134.47, 89.76)$ is more informative than those distributions. Because our prior distribution is centered around a high value of $\pi$, our posterior distribution is also centered around high values of $\pi$, or lower values of $\psi$. Because of this, our efficacy confidence intervals and p-values are not as extreme as the other distributions.

## Bootstrapping Results
The distribution of $\hat{\psi}$ from the 10,000 samples is displayed below. 

```{r bootstrap, cache=TRUE, echo=FALSE}
set.seed(1130)
x_pop <- c(rep(1, 8), rep(0, 17403))
y_pop <- c(rep(1, 162), rep(0, 17349))

pi_hat_x <- 8 / (17411)
pi_hat_y <- 162 / (17511)

efficacy_initial <- (pi_hat_y - pi_hat_x)/pi_hat_y

B <- 10000

psi_stars <- lapply(1:B, FUN = function(i){
  samp_x <- sample(x_pop, length(x_pop), replace=T)
  samp_y <- sample(y_pop, length(y_pop), replace=T)
  xbar_star <- mean(samp_x)
  ybar_star <- mean(samp_y)
  psi_star <- (ybar_star - xbar_star) / ybar_star
  data.frame(psi_star)
})

psi_star_df <- data.frame(do.call(rbind, psi_stars))

ggplot(data=psi_star_df, mapping=aes(x=psi_star)) + 
  geom_histogram(binwidth = 0.004) +
  labs(title="Histogram of 10000 Bootstrapped Efficacy Values",
       x="Efficacy",
       y="Count"
       )
efficacy_se <- sd(psi_star_df$psi_star)


upper_efficacy <- efficacy_initial + 1.96 * efficacy_se
lower_efficacy <- efficacy_initial - 1.96 * efficacy_se

upper_efficacy_quantile <- quantile(psi_star_df$psi_star, probs=0.975)
lower_efficacy_quantile <- quantile(psi_star_df$psi_star, probs=0.025)

```

Recall from the Bootstrapping Section of Statistical Methods, $\hat{\psi} = 0.950334$. The 10,000 sampled $\hat{\psi}$ generated a standard error (sample standard deviation) of `r efficacy_se`. Thus, the lower bound of the 95% Wald's confidence interval is `r lower_efficacy`, and the upper bound is `r upper_efficacy`. The 2.5th quantile of the bootstrapped data is `r lower_efficacy_quantile` and the 97.5th quantile is `r upper_efficacy_quantile`.

## Maximum Likelihood Estimation and Hypothesis Testing Results
From before, we can see that $\hat{\psi}^{mle} = \frac{77}{81} = 0.950617$. Additionally, $SE(\hat{\psi}^{mle}) = 0.01788532$. From this, we can calculate the 95% Wald's confidence interval for $\psi$, which has a lower bound of $0.915562$ and an upper bound of $0.985673$. Finally, from our hypothesis test with $H_0: \psi = 0.3$ and $H_a: \psi \neq 0.3$, we observe a W statistic of 121.6012. The probability of observing a value as or more extreme than our observed W is $2.822313 * 10^{-28}$.

## Comparing Intervals

\begin{table}[h]
\centering
\begin{tabular}{cccc} \hline
Interval & Lower Bound & Upper Bound \\ \hline
Bootstrapped Wald's & 0.914996 & 0.985671 \\ \hline
Bootstrapped Quantile & 0.911057 & 0.981714 \\ \hline
MLE Wald's & 0.915562 & 0.985673 \\ \hline
\end{tabular}
\end{table}

# Conclusion

The results of the Pfizer analysis agreed with our analysis. All methods employed estimated efficacy to be about 95%, which is also what Pfizer's estimated efficacy is as well. Additionally, all confidence intervals lined up with Pfizer's analysis, generating ranges from around 0.91 to 0.98. Since none of the confidence intervals contain 0.3, for each and every method used we reject the null hypothesis and conclude that the true efficacy is not 0.3. In addition to confidence intervals, we performed the likelihood ratio test which generated a p-value of $2.822313 * 10^{-28}$. Since this p-value is less than the specified 0.05 significance level, we conclude there is sufficient evidence against and reject the null hypothesis. Nonparametric bootstrapping is an effective tactic to model population data from a sample and generate two types of confidence intervals. However, nonparametric bootstrapping is at the mercy of the data. Inherent differences in the groups given the vaccine versus the placebo can lead to skewed data supporting a false conclusion. More analysis will need to be done on the subgroups within the data ensuring the groups are equal in participation from specific subgroups like race, obesity, age, and health status. The maximum likelihood estimation method generates a consistent estimator, giving us a reliable estimate and confidence interval for efficacy. Additionally, we can use the likelihood ratio test to determine how unusual our data is under the null hypothesis. However, the distribution for $T$, based on the distributions of $X$ and $Y$, are reliant on a few assumptions, including that every patient's COVID outcome is independent of all others and that the probability of contracting COVID is equivalent for each patient in the vaccine group and equal for each patient in the control group. However, since background factors may impact the probability of getting COVID, this is likely an untrue assumption. Nonetheless, all methods used generated an estimated efficacy of 95% with confidence intervals roughly ranging from 91% to 98%. Since each method independently rejected the null hypothesis, we agree with Pfizer and conclude that the true efficacy is not 30% but estimated to be 95%. So, the vaccine is a very effective treatment to prevent COVID-19.

# References
CDC COVID stats: https://www.cdc.gov/nchs/products/databriefs/db427.htm

# Appendix

## Equation 1: Proof of Distribution of T

First, note that since both $X$ and $Y$ have a very large number of trials with a low probability of contracting COVID, we can say that $X \approx Pois(17411 * \pi_1)$ is independent of $Y \approx Pois(17511, * \pi_2)$. 

\begin{align*}
P(T=t) &= P(X=x|X+Y=170) \text{ Probability of $x$ people in vaccine group with COVID given 170 total COVID cases} \\
&= \frac{P(X = t \cap X+Y = 170)}{P(X+Y = 170)} \text{by definition of conditional probability} \\
&= \frac{P(X = t \cap Y = 170-t)}{P(X+Y=170)} \\
&= \frac{P(X = t) * P(Y = 170-t)}{P(X+Y=170)} \text{since $X$ is independent of $Y$} \\
&= \binom{170}{t} \pi^t (1-\pi)^{170-t} \text{where $\pi = \frac{n_1\pi_1}{n_1\pi_1 + n_2\pi_2}$}
\end{align*} 
Since $n_1 = 17411 \approx 17511 = n_2$, we can substitute $n_2$ for $n_1$ and see that $\pi = \frac{n_1\pi_1}{n_1\pi_1 + n_2\pi_2} \approx \frac{n_1\pi_1}{n_1\pi_1 + n_1\pi_2} = \frac{n_1\pi_1}{n_1(\pi_1 + \pi_2)} = \frac{\pi_1}{\pi_1 + \pi_2}$.

## Equation 2: Derivation of Log Likelihood and Calculations for Maximum Likelihood Estimator for Psi

First, note that $\frac{d}{d\psi} (\frac{\psi - 1}{\psi - 2}) = \frac{-1}{(\psi - 2)^2}$ by the quotient rule, so $\frac{d}{d\psi} (1 - \frac{\psi - 1}{\psi - 2}) = \frac{1}{(\psi - 2)^2}$. Also, $\frac{1}{1 - \frac{(\psi-1)}{\psi-2}} = \frac{1}{\frac{\psi -2 - \psi + 1}{\psi-2}} = -(\psi-2)$. Now,

\begin{align*}
\frac{d}{d\psi} (\ell(\psi)) &= 0 + 8 * \frac{\psi - 2}{\psi - 1} * \frac{d}{d\psi} (\frac{\psi - 1}{\psi - 2})  + 162 * \frac{1}{1 - \frac{\psi-1}{\psi-2}} * \frac{d}{d\psi} (1 - \frac{\psi-1}{\psi-2})  \\
&= \frac{-8(\psi-2)}{(\psi-1)(\psi-2)^2} - \frac{162(\psi-2)}{(\psi-2)^2} \\
&= \frac{-8}{(\psi-1)(\psi-2)} - \frac{162}{\psi-2} = 0 \\
& \text{ and } \\
\frac{-8}{(\psi-1)(\psi-2)} - \frac{162(\psi-1)}{(\psi -1)(\psi-2)} &= 0 \\
-8 - 162(\psi-1) &= 0 \\
-8 -162 \psi + 162 &= 0 \\
-162 \psi &= -154 \\
\psi &= \frac{-154}{-162} = \frac{77}{81}
\end{align*}

## Equation 3: Second Derivative of Log Likelihood

\begin{align*}
\frac{d^2}{d^2\psi} \ell(\psi) = \frac{d}{d\psi} \ell ' (\psi) &= \frac{d}{d\psi} (\frac{-8}{(\psi-1)(\psi-2)} - \frac{162}{\psi-2}) \\
&= \frac{d}{d\psi} (-8(\psi^2 -3\psi + 2)^{-1} - 162(\psi-2)^{-1}) \\
&= \frac{8}{(\psi^2 -3\psi + 2)^2} * \frac{d}{d\psi} (\psi^2 -3\psi + 2) + \frac{162}{\psi-2)^2} * \frac{d}{d\psi} (\psi - 2) \\
&= \frac{8 * (2\psi -3)}{(\psi^2 -3\psi + 2)^2} + \frac{162}{\psi-2)^2}
\end{align*}

## Code Chunk 1: Prior Parameters
```{r, eval=FALSE}
beta.select(quantile1 = list(p=0.05, x=0.4118),
            quantile2 = list(p=0.5, x=0.5))
```

## Code Chunk 2: Bayesian Calculations
```{r efficacy, eval=FALSE}
# converts from pi values to efficacy values (psi)
efficacy <- function(pi) {
  return ((1 - 2*pi) / (1 - pi))
}
```

```{r Bayesian uniform, eval=FALSE}
# calculate posterior median
posterior_median_pi <- qbeta(0.5, shape1 = 1 + 8, shape2 = 1 + 170 - 8)
cat("posterior median:", efficacy(posterior_median_pi), "\n")

# calculate 95% CI
pi_ci_unif <- qbeta(p = c(0.025, 0.975), shape1 = 1 + 8, shape2 = 170 - 8 + 1)
low_unif <- efficacy(pi_ci_unif[2])
high_unif <- efficacy(pi_ci_unif[1])

# calculate 1-sided p-value
cat("1-sided p-value: ", pbeta(q=0.4118, shape1=1 + 8, shape2=1 + 170 - 8, lower.tail=FALSE), "\n")

cat("95% CI:", c(low_unif, high_unif))
```

```{r Bayesian study, eval=FALSE}
# calculate posterior median
posterior_median_pi <- qbeta(0.5, shape1 = 0.700102 + 8, shape2 = 1 + 170 - 8)
cat("posterior median:", efficacy(posterior_median_pi), "\n")

# calculate 95% CI
pi_ci_study <- qbeta(p = c(0.025, 0.975), shape1 = 0.700102 + 8, shape2 = 170 - 8 + 1)
low_study <- efficacy(pi_ci_study[2])
high_study <- efficacy(pi_ci_study[1])

# calculate 1-sided p-value
cat("1-sided p-value: ", pbeta(q=0.4118, shape1=0.700102 + 8, shape2=1 + 170 - 8, lower.tail=FALSE), "\n")

cat("95% CI:", c(low_study, high_study))
```

```{r Bayesian med0, eval=FALSE}
# calculate posterior median
posterior_median_pi <- qbeta(0.5, shape1 = 43.04 + 8, shape2 = 43.04 + 170 - 8)
cat("posterior median:", efficacy(posterior_median_pi), "\n")

# calculate 95% CI
pi_ci_med0 <- qbeta(p = c(0.025, 0.975), shape1 = 43.04 + 8, shape2 = 43.04 + 170 - 8)
low_med0 <- efficacy(pi_ci_med0[2])
high_med0 <- efficacy(pi_ci_med0[1])

# calculate 1-sided p-value
cat("1-sided p-value: ", pbeta(q=0.4118, shape1=43.04 + 8, shape2=43.04 + 170 - 8, lower.tail=FALSE), "\n")

cat("95% CI:", c(low_med0, high_med0))
```

```{r Bayesian pessimistic, eval=FALSE}
# calculate posterior median
posterior_median_pi <- qbeta(0.5, shape1 = 134.47 + 8, shape2 = 89.76 + 170 - 8)
cat("posterior median:", efficacy(posterior_median_pi), "\n")

# calculate 95% CI
pi_ci_med0 <- qbeta(p = c(0.025, 0.975), shape1 = 134.47 + 8, shape2 = 89.76 + 170 - 8)
low_med0 <- efficacy(pi_ci_med0[2])
high_med0 <- efficacy(pi_ci_med0[1])

# calculate 1-sided p-value
cat("1-sided p-value: ", pbeta(q=0.4118, shape1=134.47 + 8, shape2=89.76 + 170 - 8, lower.tail=FALSE), "\n")


cat("95% CI:", c(low_med0, high_med0))
```


## Code Chunk 3: Bootstrapping
```{r bootstrapping, eval=FALSE}
set.seed(1130)
x_pop <- c(rep(1, 8), rep(0, 17403))
y_pop <- c(rep(1, 162), rep(0, 17349))

pi_hat_x <- 8 / (17411)
pi_hat_y <- 162 / (17511)

efficacy_initial <- (pi_hat_y - pi_hat_x)/pi_hat_y

B <- 10000

psi_stars <- lapply(1:B, FUN = function(i){
  samp_x <- sample(x_pop, length(x_pop), replace=T)
  samp_y <- sample(y_pop, length(y_pop), replace=T)
  xbar_star <- mean(samp_x)
  ybar_star <- mean(samp_y)
  psi_star <- (ybar_star - xbar_star) / ybar_star
  data.frame(psi_star)
})

psi_star_df <- data.frame(do.call(rbind, psi_stars))

ggplot(data=psi_star_df, mapping=aes(x=psi_star)) + 
  geom_histogram(binwidth = 0.004) +
  labs(title="Histogram of 10000 Bootstrapped Efficacy Values",
       x="Efficacy",
       y="Count"
       )
efficacy_se <- sd(psi_star_df$psi_star)
efficacy_se

upper_efficacy <- efficacy_initial + 1.96 * efficacy_se
lower_efficacy <- efficacy_initial - 1.96 * efficacy_se
c(lower_efficacy, upper_efficacy)

upper_efficacy_quantile <- quantile(psi_star_df$psi_star, probs=0.975)
lower_efficacy_quantile <- quantile(psi_star_df$psi_star, probs=0.025)
c(lower_efficacy_quantile, upper_efficacy_quantile)

```