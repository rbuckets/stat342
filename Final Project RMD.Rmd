---
title: "Descriptive, Interesting Title"
author: "Trevor Riordan, Ray Wang"
date: "2023-05-26"
output: pdf_document
header-includes: \usepackage{setspace}\doublespacing
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
```

# Abstract

# Introduction

# Keywords

# Introduction

# Statistical Methods

## Bayesian



## Nonparametric Bootstrapping

This section details the method of nonparametric bootstrapping to generate two forms of confidence intervals providing insight into the true efficacy rate of the vaccine. From Table 2 of the referenced paper we are given two groups of patients: those given the vaccine and those given placebo. From those given the vaccine we can measure the number who got COVID and call this value x and from those given the placebo we can measure the same thing, calling this value y. Then, because there are a fixed number of patients per group who either contract COVID (which is considered the "success" here) or not, and under the assumption that every patient has equal probability of contracting COVID and that the result of one patient does not impact any others, we can model X, the number of COVID cases from the vaccine group, and Y, the number of COVID cases from the placebo group, as binomial distributions. From the table we can see there are $8+17411 = 17419$ patients given the vaccine and $162 + 17511 = 17673$ given the placebo. Thus, $X \sim Binom(17419, \pi_1)$ and $Y \sim Binom(17673, \pi_2)$ where $\pi_1$ is the probability of any given patient with the vaccine contracting COVID and $\pi_2$ is the probability of contracting COVID given the placebo. We can then measure efficacy, $\psi$, as the reduction in probability of contracting COVID given the vaccine compared to the placebo by $\psi = \frac{\pi_2 - \pi_1}{\pi_2}$. We know the expected value of a binomial distribution with $n$ trials and $\pi_0$ probability of success is $n \pi_0$. Using method of moments to equate the sample mean, $\bar{x}$, to the expected value, we get that an estimate for $\pi_0$ is $\hat{\pi_0}^{mom} = \frac{\bar{x}}{n}$. Treating the given data as the population data, we can sample data of the same size as the original samples with replacement from the observed $X$ and the observed $Y$ samples, each 10,000 times. From each of these 10,000 bootstrapped samples from $X$ and $Y$, we can calculate an estimate for both $\pi_1$ and $\pi_2$ and thus create 10,000 sampled $\hat{\psi} = \frac{\hat{\pi_2} - \hat{\pi_1}}{\hat{\pi_2}}$, accurately representing the distribution of $\hat{\psi}$. From these 10,000 samples we can calculate the standard error of $\hat{\psi}$. Since we have a large number of observations (10,000), we know the distribution of $\hat{\psi}$ is approximately normal, so we can create a 95% confidence interval by adding or subtracting the standard error multiplied by 1.96 to or from our observed efficacy value to generate a range of values we are 95% confident contains the true efficacy of the vaccine. Additionally, we can create a 95% confidence interval ranging from the 2.5th to the 97.5th quantile of our 10,000 sampled $\hat{\psi}$ which we are 95% confident contains the true efficacy of the vaccine. 

## Maximum Likelihood Estimator and Hypothesis Testing

This section details the use of the maximum likelihood estimator for $\psi$ giving the most probable $\psi$ under our observed data. Additionally, we will perform hypothesis testing determining the probability of observing data at least as extreme as our data under the null hypothesis, indicating how likely it is the null hypothesis is true. For both maximum likelihood estimation and hypothesis testing, we aggregate our observed data into a single binomial distribution. Let T be the number of patients in the vaccine group out of all patients who contracted COVID, then, $T \sim Binom(S=170, \pi_0)$ where $S=162 + 8 = 170$ is the total number of patients who contracted COVID from our data and $\pi_0 = \frac{\pi_1}{\pi_1 + \pi_2}$ represents the probability of being in the vaccine group given the patient contracted COVID (this is the proportion of having the vaccine and COVID out of all those who contracted COVID, regardless of group). This distribution works since we have a fixed number of trials (170 COVID cases) that are either in the vaccine group (success) or not, and we can assume that each patient has equal chance of being in the vaccine group given they have COVID while the outcome of having the vaccine or not is independent of the other patients. Note from before that $\psi = \frac{\pi_2 - \pi_1}{\pi_2}$, substituting $\pi_0 = \frac{\pi_1}{\pi_1 + \pi_2}$ we get $\psi = \frac{1- 2\pi_0}{1-\pi_0}$ and thus $\pi_0 = \frac{1 - \psi}{1 - 2 \psi}$. So, $T \sim Binom(170, \pi_0 = \frac{1 - \psi}{1 - 2 \psi})$.  Because $T \sim Binom(170, \pi_0 = \frac{1 - \psi}{1 - 2 \psi})$ and we have only observation for $t = \text{Number of Patients Given Vaccine Out of All COVID Cases}$, substituting $\pi_0 = \frac{1 - \psi}{1 - 2 \psi}$ into $f(t) = \binom{170}{t} * \pi_0^t * (1-\pi_0)^{170-t}$ yields the likelihood function $L(\psi) = \binom{170}{t} * (\frac{1 - \psi}{1 - 2 \psi})^x * (1 - (\frac{1 - \psi}{1 - 2 \psi}))^{170 - t}$. Thus, the log-likelihood function $\ell(\psi) = \ln(\binom{170}{t}) + t * \ln(\frac{1 - \psi}{1 - 2 \psi}) + (170 - t) \ln(1-(\frac{1 - \psi}{1 - 2 \psi}))$. Next, we will take the derivative of the log-likelihood function and set it equal to 0 to solve for the maximum likelihood estimator for $\psi$. Note that $\frac{d}{d\psi} (\frac{1 - \psi}{1 - 2 \psi}) = \frac{-1}{(\psi - 2)^2}$ by the quotient rule, so $\frac{d}{d\psi} (1 - \frac{1 - \psi}{1 - 2 \psi}) = \frac{1}{(\psi - 2)^2}$. Also, $\frac{1}{1 - \frac{(1-\psi)}{2-\psi}} = \frac{1}{\frac{2 - \psi + \psi - 1}{2-\psi}} = \frac{2-\psi}{1}$ 
Now, 
\begin{align*}
\frac{d}{d\psi} (\ell(\psi)) &= 0 + t * \frac{2 - \psi}{1-\psi} * \frac{d}{d\psi} (\frac{1 - \psi}{1 - 2 \psi})  + (170 - t) \frac{1}{1 - \frac{(1-\psi)}{2-\psi}} * \frac{d}{d\psi} (1 - \frac{1 - \psi}{1 - 2 \psi})  \\
&= \frac{-t(2-\psi)}{(1-\psi)(2-\psi)^2} + \frac{(170 -t)(2-\psi)}{(\psi-2)^2} \\
&= \frac{-t}{(1-\psi)(2-\psi)} + \frac{(t - 170)}{(2-\psi)}
\end{align*}


```{r bootstrapping, cache=TRUE, echo=FALSE}
set.seed(1130)
x_pop <- c(rep(1, 8), rep(0, 17411))
y_pop <- c(rep(1, 162), rep(0, 17511))

pi_hat_x <- 8 / (8 + 17411)
pi_hat_y <- 162 / (162 + 17511)

efficacy_initial <- (pi_hat_y - pi_hat_x)/pi_hat_y

B <- 10000

psi_stars <- lapply(1:B, FUN = function(i){
  samp_x <- sample(x_pop, length(x_pop), replace=T)
  samp_y <- sample(y_pop, length(y_pop), replace=T)
  xbar_star <- mean(samp_x)
  ybar_star <- mean(samp_y)
  psi_star <- (ybar_star - xbar_star) / ybar_star
  data.frame(psi_star)
})

psi_star_df <- data.frame(do.call(rbind, psi_stars))

ggplot(data=psi_star_df, mapping=aes(x=psi_star)) + 
  geom_histogram(binwidth = 0.004) +
  labs(title="Histogram of 10000 Bootstrapped Efficacy Values",
       x="Efficacy",
       y="Count"
       )
efficacy_se <- sd(psi_star_df$psi_star)
efficacy_se

upper_efficacy <- efficacy_initial + 1.96 * efficacy_se
lower_efficacy <- efficacy_initial - 1.96 * efficacy_se
c(lower_efficacy, upper_efficacy)

upper_efficacy_quantile <- quantile(psi_star_df$psi_star, probs=0.975)
lower_efficacy_quantile <- quantile(psi_star_df$psi_star, probs=0.025)
c(lower_efficacy_quantile, upper_efficacy_quantile)

```

# Results

# Conclusion

# References

# Appendix


